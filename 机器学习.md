 # 有监督学习
 ## 线性回归
 ## 正则化

 ## 逻辑回归
 有监督学习的分类任务
 ## 支持向量机（support vector machine,SVM）
 可用于分类、回归
 ## 支持向量机核方法
 ## 朴素贝叶斯
 常用于自然语言分类如垃圾邮件过滤

 ## 随机森林
 是将多个模型综合起来创建更高性能模型的方法，可用于回归、分类
 随机森林的目标是利用多个决策树模型，获得比单个决策树更高的预测精度
-（1）随机森林优点
1. 对于高维（特征很多）稠密型的数据适用，不用降维，无需做特征选择。
2. 构建随机森林模型的过程，亦可帮助判断特征的重要程度。
3. 可以借助模型构建组合特征。
4. 并行集成，有效控制过拟合。
5. 工程实现并行简单，训练速度快。
6. 对于不平衡的数据集友好，可以平衡误差。
7. 对于特征确实鲁棒性强，可以维持不错的准确度。
-（2）随机森林缺点
1. 在噪声过大的分类和回归数据集上还是可能会过拟合。
2. 相比单一决策树，因其随机性，模型解释会更复杂一些。
 ## 神经网络
 ## KNN(K近邻)
 可用于分类、回归
 KNN在训练时机械的记住所有数据，在对未知数据进行分类时，KNN计算未知数据与训练数据的距离通过多数表决找到最近邻的k个点然后分类。
 适用于具有复杂边界的数据
 当数据量较小或维度较小时，KNN效果很好，但是数据量或维度较大时，就需要考虑其他方法
 # 无监督学习
 ## PCA主成分分析
 降维算法
 ## 
 ## 
 ## 
 ## 